// ===================================
// Project Modal System
// ===================================

// Project data with full details in English and German
const projectsData = {
    'project-1': {
        en: {
            tag: 'ðŸ¥‡ Bachelor\'s Thesis',
            title: 'AI Vision-Controlled Robotic Hand',
            description: 'Real-time computer vision system integrated with robotic hardware for gesture-based control. This project demonstrates end-to-end AI deployment from perception to physical actuation, combining YOLOv8 object detection, custom dataset creation, and embedded systems control. The system achieves low-latency real-time performance, bridging human intent with machine execution through computer vision and robotics integration.',
            technologies: ['Python', 'YOLOv8', 'OpenCV', 'Arduino', 'PySerial', 'Roboflow', 'NumPy', 'Servo Motors', '3D Printing'],
            features: [
                'ðŸ§  Real-time hand detection and tracking using YOLOv8',
                'ðŸ“¸ Custom dataset creation with Roboflow annotation',
                'âš¡ Low-latency serial communication (Python â†” Arduino)',
                'ðŸ¤– 5-finger independent servo motor control',
                'ðŸ”„ End-to-end pipeline: perception â†’ decision â†’ actuation',
                'ðŸ›¡ï¸ Safety features: auto-release timeout and fail-safe reset',
                'ðŸŽ¯ Optimized inference for real-time hardware control',
                'ðŸ”§ Hardware-aware software engineering'
            ],
            links: [
                { text: 'View on GitHub', url: 'https://github.com/BUAksakal/ai-vision-robotic-hand', icon: 'github' }
            ],
            visuals: [
                { path: 'images/robotic_hand_cad.png', caption: '3D Printed Robotic Hand Design' },
                { path: 'images/yolo_detection_grid.png', caption: 'YOLOv8 Hand Gesture Detection' }
            ]
        },
        de: {
            tag: 'ðŸ¥‡ Bachelorarbeit',
            title: 'KI-Vision-gesteuerte Roboterhand',
            description: 'Echtzeit-Computer-Vision-System integriert mit Roboterhardware fÃ¼r gestenbasierte Steuerung. Dieses Projekt demonstriert eine End-to-End-KI-Bereitstellung von der Wahrnehmung bis zur physischen BetÃ¤tigung und kombiniert YOLOv8-Objekterkennung, benutzerdefinierte Datensatzerstellung und Steuerung eingebetteter Systeme. Das System erreicht eine geringe Latenzzeit in Echtzeit und verbindet menschliche Absicht mit maschineller AusfÃ¼hrung durch die Integration von Computer Vision und Robotik.',
            technologies: ['Python', 'YOLOv8', 'OpenCV', 'Arduino', 'PySerial', 'Roboflow', 'NumPy', 'Servomotoren', '3D-Druck'],
            features: [
                'ðŸ§  Echtzeit-Handerkennung und -verfolgung mit YOLOv8',
                'ðŸ“¸ Benutzerdefinierte Datensatzerstellung mit Roboflow-Annotation',
                'âš¡ Serielle Kommunikation mit geringer Latenz (Python â†” Arduino)',
                'ðŸ¤– UnabhÃ¤ngige Servomotorsteuerung fÃ¼r 5 Finger',
                'ðŸ”„ End-to-End-Pipeline: Wahrnehmung â†’ Entscheidung â†’ BetÃ¤tigung',
                'ðŸ›¡ï¸ Sicherheitsfunktionen: Auto-Release-Timeout und Fail-Safe-Reset',
                'ðŸŽ¯ Optimierte Inferenz fÃ¼r Echtzeit-Hardwaresteuerung',
                'ðŸ”§ Hardware-nahe Softwareentwicklung'
            ],
            links: [
                { text: 'Auf GitHub ansehen', url: 'https://github.com/BUAksakal/ai-vision-robotic-hand', icon: 'github' }
            ],
            visuals: [
                { path: 'images/robotic_hand_cad.png', caption: '3D-gedrucktes Roboterhand-Design' },
                { path: 'images/yolo_detection_grid.png', caption: 'YOLOv8 Handgestenerkennung' }
            ]
        }
    },
    'project-2': {
        en: {
            tag: 'ðŸ“± Master\'s Course',
            title: 'AI-Powered Fitness Tracker',
            description: 'Cross-platform mobile fitness application combining Flutter development, Firebase backend, and AI-driven workout recommendations. Developed as a Master\'s course project at Deggendorf Institute of Technology, this app demonstrates end-to-end mobile product development with cloud integration and personalized training insights based on historical activity data.',
            technologies: ['Flutter', 'Dart', 'Firebase', 'Python', 'NumPy', 'Cloud Firestore', 'Firebase Auth'],
            features: [
                'ðŸ“± Cross-platform mobile app (Android & iOS)',
                'ðŸ” Firebase authentication and cloud storage',
                'ðŸ“Š Historical workout tracking and analytics',
                'ðŸ§  AI-driven personalized workout recommendations',
                'âš¡ Real-time data synchronization',
                'ðŸ“ˆ Progress monitoring and visualization',
                'ðŸŽ¯ Rule-based recommendation engine',
                'ðŸ’ª Balanced muscle group distribution suggestions'
            ],
            links: [
                { text: 'App UI Repository', url: 'https://github.com/BUAksakal/AI-FitnessTracker', icon: 'github' },
                { text: 'AI Recommendation System', url: 'https://github.com/BUAksakal/smart-fitness-recommender-system', icon: 'github' }
            ],
            visuals: [
                { path: 'images/dumbbelly_exact_ref.png', caption: 'Dumbbelly - Mobile App Interface' },
                { path: 'images/fitness_recommendation_flow.png', caption: 'AI Recommendation System Flow' }
            ]
        },
        de: {
            tag: 'ðŸ“± Master-Kurs',
            title: 'KI-gestÃ¼tzter Fitness-Tracker',
            description: 'PlattformÃ¼bergreifende mobile Fitnessanwendung, die Flutter-Entwicklung, Firebase-Backend und KI-gesteuerte Trainingsempfehlungen kombiniert. Entwickelt als Master-Kursprojekt an der Technischen Hochschule Deggendorf, demonstriert diese App eine End-to-End-Mobilproduktentwicklung mit Cloud-Integration und personalisierten Trainingseinblicken auf der Grundlage historischer AktivitÃ¤tsdaten.',
            technologies: ['Flutter', 'Dart', 'Firebase', 'Python', 'NumPy', 'Cloud Firestore', 'Firebase Auth'],
            features: [
                'ðŸ“± PlattformÃ¼bergreifende mobile App (Android & iOS)',
                'ðŸ” Firebase-Authentifizierung und Cloud-Speicher',
                'ðŸ“Š Historische Trainingsverfolgung und Analysen',
                'ðŸ§  KI-gesteuerte personalisierte Trainingsempfehlungen',
                'âš¡ Echtzeit-Datensynchronisation',
                'ðŸ“ˆ FortschrittsÃ¼berwachung und Visualisierung',
                'ðŸŽ¯ Regelbasierte Empfehlungs-Engine',
                'ðŸ’ª VorschlÃ¤ge fÃ¼r ausgewogene Muskelgruppenverteilung'
            ],
            links: [
                { text: 'App UI Repository', url: 'https://github.com/BUAksakal/AI-FitnessTracker', icon: 'github' },
                { text: 'KI-Empfehlungssystem', url: 'https://github.com/BUAksakal/smart-fitness-recommender-system', icon: 'github' }
            ],
            visuals: [
                { path: 'images/dumbbelly_exact_ref.png', caption: 'Dumbbelly - Mobile App Interface' },
                { path: 'images/fitness_recommendation_flow.png', caption: 'KI-Empfehlungssystem-Ablauf' }
            ]
        }
    },
    'project-3': {
        en: {
            tag: 'ðŸ›°ï¸ Industry Internship',
            title: 'LiDAR-Based Mapping & SLAM System',
            description: 'Real-time environment perception and mapping system developed during a long-term industry internship. The project focused on processing LiDAR sensor data, building spatial representations, and evaluating localization performance using SLAM approaches in simulation-based workflows. Emphasis on understanding real-time robotic perception, sensor behavior, and data-driven environment modeling for navigation analysis.',
            technologies: ['Python', 'Gazebo', 'LiDAR Sensors', 'SLAM', 'Robotics Simulation', 'Sensor Processing'],
            features: [
                'ðŸ›°ï¸ LiDAR sensor data acquisition and processing',
                'ðŸ—ºï¸ Real-time environment mapping and localization',
                'ðŸ¤– SLAM algorithm implementation and evaluation',
                'âš™ï¸ Gazebo simulation for robotics testing',
                'ðŸ“Š Sensor-based environment modeling',
                'ðŸŽ¯ Navigation-oriented perception workflows',
                'âš¡ Real-time data handling pipelines',
                'ðŸ”¬ Structured evaluation of mapping quality'
            ],
            links: [
                { text: 'View on GitHub', url: 'https://github.com/BUAksakal/lidar-slam-mapping-system', icon: 'github' }
            ],
            visuals: [
                { path: 'images/lidar_map_visualization.png', caption: 'LiDAR Occupancy Grid Map' },
                { path: 'images/gazebo_simulation_scene.png', caption: 'Gazebo Simulation Environment' }
            ]
        },
        de: {
            tag: 'ðŸ›°ï¸ Industriepraktikum',
            title: 'LiDAR-basiertes Mapping & SLAM-System',
            description: 'Echtzeit-Umgebungswahrnehmungs- und Kartierungssystem, entwickelt wÃ¤hrend eines langfristigen Industriepraktikums. Das Projekt konzentrierte sich auf die Verarbeitung von LiDAR-Sensordaten, den Aufbau rÃ¤umlicher Darstellungen und die Bewertung der Lokalisierungsleistung unter Verwendung von SLAM-AnsÃ¤tzen in simulationsbasierten Workflows. Schwerpunkt auf dem VerstÃ¤ndnis von Echtzeit-Roboterwahrnehmung, Sensorverhalten und datengesteuerter Umgebungsmodellierung fÃ¼r die Navigationsanalyse.',
            technologies: ['Python', 'Gazebo', 'LiDAR-Sensoren', 'SLAM', 'Robotersimulation', 'Sensorverarbeitung'],
            features: [
                'ðŸ›°ï¸ LiDAR-Sensordatenerfassung und -verarbeitung',
                'ðŸ—ºï¸ Echtzeit-Umgebungskartierung und -lokalisierung',
                'ðŸ¤– SLAM-Algorithmus-Implementierung und -Bewertung',
                'âš™ï¸ Gazebo-Simulation fÃ¼r Robotertests',
                'ðŸ“Š Sensorbasierte Umgebungsmodellierung',
                'ðŸŽ¯ Navigationsorientierte Wahrnehmungsworkflows',
                'âš¡ Echtzeit-Datenverarbeitungspipelines',
                'ðŸ”¬ Strukturierte Bewertung der KartierungsqualitÃ¤t'
            ],
            links: [
                { text: 'Auf GitHub ansehen', url: 'https://github.com/BUAksakal/lidar-slam-mapping-system', icon: 'github' }
            ],
            visuals: [
                { path: 'images/lidar_map_visualization.png', caption: 'LiDAR Belegungsgitterkarte' },
                { path: 'images/gazebo_simulation_scene.png', caption: 'Gazebo Simulationsumgebung' }
            ]
        }
    },
    'project-4': {
        en: {
            tag: 'ðŸ’§ Industry Internship',
            title: 'Smart Water Meter Monitoring System',
            description: 'Industrial IoT data engineering system developed during internship at Baylan Water & Energy Meters. The project bridges LoRaWAN-enabled smart water meters with operator monitoring interfaces through payload decoding, real-time data processing, and multi-platform visualization. Demonstrates practical experience with industrial telemetry workflows, event-driven architecture, and IoT communication protocols in a production environment.',
            technologies: ['Python', 'LoRaWAN', 'Tkinter', 'Streamlit', 'Pandas', 'Watchdog', 'JSON', 'Event-Driven Architecture'],
            features: [
                'ðŸ›°ï¸ LoRaWAN payload decoding and protocol interpretation',
                'ðŸ“Š Real-time telemetry data processing and visualization',
                'ðŸ–¥ï¸ Desktop monitoring interface with Tkinter',
                'ðŸŒ Web-based live dashboard with Streamlit',
                'âš¡ Event-driven file monitoring with Watchdog',
                'ðŸ”„ Automated data refresh and background service orchestration',
                'ðŸ“ˆ Voltage, credit, and battery status extraction',
                'âš™ï¸ Multi-interface architecture (desktop + web)',
                'ðŸ­ Industrial-grade monitoring workflow',
                'ðŸ”§ Modular data pipeline design'
            ],
            links: [
                { text: 'View on GitHub', url: 'https://github.com/BUAksakal/smart-water-meter-monitoring-system', icon: 'github' }
            ],
            visuals: [
                { path: 'images/water_meter_architecture.png', caption: 'System Architecture & Data Flow' },
                { path: 'images/baylan_interface.png', caption: 'Baylan Payload System Interface' }
            ]
        },
        de: {
            tag: 'ðŸ’§ Industriepraktikum',
            title: 'Intelligentes WasserzÃ¤hler-Ãœberwachungssystem',
            description: 'Industrielles IoT-Data-Engineering-System, entwickelt wÃ¤hrend eines Praktikums bei Baylan Water & Energy Meters. Das Projekt verbindet LoRaWAN-fÃ¤hige intelligente WasserzÃ¤hler mit BetreiberÃ¼berwachungsschnittstellen durch Payload-Decodierung, Echtzeit-Datenverarbeitung und plattformÃ¼bergreifende Visualisierung. Zeigt praktische Erfahrung mit industriellen Telemetrie-Workflows, ereignisgesteuerter Architektur und IoT-Kommunikationsprotokollen in einer Produktionsumgebung.',
            technologies: ['Python', 'LoRaWAN', 'Tkinter', 'Streamlit', 'Pandas', 'Watchdog', 'JSON', 'Ereignisgesteuerte Architektur'],
            features: [
                'ðŸ›°ï¸ LoRaWAN-Payload-Decodierung und Protokollinterpretation',
                'ðŸ“Š Echtzeit-Telemetriedatenverarbeitung und -visualisierung',
                'ðŸ–¥ï¸ Desktop-Ãœberwachungsschnittstelle mit Tkinter',
                'ðŸŒ Webbasiertes Live-Dashboard mit Streamlit',
                'âš¡ Ereignisgesteuerte DateiÃ¼berwachung mit Watchdog',
                'ðŸ”„ Automatisierte Datenaktualisierung und Hintergrunddienst-Orchestrierung',
                'ðŸ“ˆ Spannungs-, Kredit- und Batteriestatus-Extraktion',
                'âš™ï¸ Multi-Schnittstellen-Architektur (Desktop + Web)',
                'ðŸ­ Industrieller Ãœberwachungsworkflow',
                'ðŸ”§ Modulares Datenpipeline-Design'
            ],
            links: [
                { text: 'Auf GitHub ansehen', url: 'https://github.com/BUAksakal/smart-water-meter-monitoring-system', icon: 'github' }
            ],
            visuals: [
                { path: 'images/water_meter_architecture.png', caption: 'Systemarchitektur & Datenfluss' },
                { path: 'images/baylan_interface.png', caption: 'Baylan Payload System Interface' }
            ]
        }
    }
};

// Get modal elements
const modal = document.getElementById('projectModal');
const modalClose = document.getElementById('modalClose');
const modalTag = document.getElementById('modalTag');
const modalTitle = document.getElementById('modalTitle');
const modalDescription = document.getElementById('modalDescription');
const modalTech = document.getElementById('modalTech');
const modalFeatures = document.getElementById('modalFeatures');
const modalLinks = document.getElementById('modalLinks');

// Function to open modal with project data
function openProjectModal(projectId) {
    // Get current language from local storage, default to 'en'
    const currentLang = localStorage.getItem('language') || 'en';

    // Access the project data for the current language
    const project = projectsData[projectId] && projectsData[projectId][currentLang];

    if (!project) return;

    // Populate modal content
    modalTag.textContent = project.tag;
    modalTitle.textContent = project.title;
    modalDescription.textContent = project.description;

    // Clear and populate technologies
    modalTech.innerHTML = '';
    project.technologies.forEach(tech => {
        const techTag = document.createElement('span');
        techTag.className = 'modal-tech-tag';
        techTag.textContent = tech;
        modalTech.appendChild(techTag);
    });

    // Clear and populate features
    modalFeatures.innerHTML = '';
    project.features.forEach(feature => {
        const li = document.createElement('li');
        li.textContent = feature;
        modalFeatures.appendChild(li);
    });

    // Clear and populate links
    modalLinks.innerHTML = '';
    project.links.forEach(link => {
        const a = document.createElement('a');
        a.href = link.url;
        a.className = 'modal-link';
        a.target = '_blank';
        a.rel = 'noopener noreferrer';

        const icon = link.icon === 'github'
            ? '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>'
            : '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg>';

        a.innerHTML = icon + '<span>' + link.text + '</span>';
        modalLinks.appendChild(a);
    });

    // Handle visuals if they exist
    const modalVisualsSection = document.getElementById('modalVisualsSection');
    const modalVisuals = document.getElementById('modalVisuals');

    if (project.visuals && project.visuals.length > 0) {
        modalVisualsSection.style.display = 'block';
        modalVisuals.innerHTML = '';

        project.visuals.forEach(visual => {
            const visualItem = document.createElement('div');
            visualItem.className = 'modal-visual-item';

            const img = document.createElement('img');
            img.src = visual.path;
            img.alt = visual.caption;
            img.className = 'modal-visual-image';

            const caption = document.createElement('p');
            caption.className = 'modal-visual-caption';
            caption.textContent = visual.caption;

            visualItem.appendChild(img);
            visualItem.appendChild(caption);
            modalVisuals.appendChild(visualItem);
        });
    } else {
        modalVisualsSection.style.display = 'none';
    }

    // Show modal
    modal.classList.add('active');
    document.body.classList.add('modal-open');
}

// Function to close modal
function closeProjectModal() {
    modal.classList.remove('active');
    document.body.classList.remove('modal-open');
}

// Add click event listeners to project cards
document.addEventListener('DOMContentLoaded', () => {
    const projectCards = document.querySelectorAll('.project-card:not(.project-card-more)');

    projectCards.forEach((card, index) => {
        const projectId = `project-${index + 1}`;
        card.style.cursor = 'pointer';

        // Click on card to open modal
        card.addEventListener('click', (e) => {
            // If clicking on any GitHub link or dual links container, let it navigate normally
            if (e.target.closest('.project-link') || e.target.closest('.project-links-dual')) {
                // Don't prevent default - let the link work
                return;
            }
            // Otherwise open the modal
            openProjectModal(projectId);
        });
    });

    // Close modal on X button click
    modalClose.addEventListener('click', closeProjectModal);

    // Close modal on overlay click (outside modal)
    modal.addEventListener('click', (e) => {
        if (e.target === modal) {
            closeProjectModal();
        }
    });

    // Close modal on ESC key
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && modal.classList.contains('active')) {
            closeProjectModal();
        }
    });
});
